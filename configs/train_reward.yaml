train:
  epochs: 1
  # total_steps: 1000
  batch_size: 2

  # checkpoint_interval: 10000 # checkpoint interval
  # eval_interval: 128

model:
  model_path: "gpt2"

tokenizer:
  tokenizer_path: "gpt2"

optimizer:
  lr: 1.0e-3

data:
  data_path: "CarperAI/openai_summarize_comparisons"
