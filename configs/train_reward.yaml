train:
  epochs: 1
  # total_steps: 1000
  batch_size: 2

  # checkpoint_interval: 10000 # checkpoint interval
  eval_interval: 1

model:
  model_path: "gpt2"

tokenizer:
  tokenizer_path: "gpt2"

optimizer:
  lr: 1.0e-3

data:
  data_path: "CarperAI/openai_summarize_comparisons"

wandb:
  project_name: "instruct_goose"
  entity: "instruct_goose"

experiment:
  name: "first_train"
  seed: 42
